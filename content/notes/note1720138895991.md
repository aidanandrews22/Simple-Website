# Research and Validate the Ability to Integrate Chatbot Functionality with API

&emsp; ***Objective:***
&emsp; &emsp; Understand how companies create and implement web apps that fine tune Open-AI api llm's.

### Research:

- **Datasets**
	- We need to find a viable dataset that will help the bot give professional advice while still coming off personable.

- **Implementation**

	- **Steps from SwirlAI**

		1. Split text corpus of the entire knowledge base into chunks - a chunk will represent a single piece of context available to be queried. Keep in mind that the data of interest can be coming from multiple sources of different types, e.g. Documentation in Confluence supplemented by PDF reports.

		2. Use the Embedding Model (explanation of what an Embedding model is and how to choose one is out of scope for this article and will be covered in the later episodes) to transform each of the chunks into a vector embedding.

		3. Store all vector embeddings in a Vector Database (We covered what a Vector DB is in an article here).

		4. Save text that represents each of the embeddings separately together with the pointer to the embedding.

		5. Embed a question/query you want to ask using the same Embedding Model that was used to embed the knowledge base itself.

		6. Use the resulting Vector Embedding to run a query against the index in Vector Database. Choose how many vectors you want to retrieve from the Vector Database - it will equal the amount of context you will be retrieving and eventually using for answering the query question.

		7. Vector DB performs an Approximate Nearest Neighbour (ANN) search for the provided vector embedding against the index and returns previously chosen amount of context vectors. The procedure returns vectors that are most similar in a given Embedding/Latent space. 

		8. Map the returned Vector Embeddings to the text chunks that represent them.

		9. Pass a question together with the retrieved context text chunks to the LLM via prompt. Instruct the LLM to only use the provided context to answer the given question. This does not mean that no Prompt Engineering will be needed - you will want to ensure that the answers returned by LLM fall into expected boundaries, e.g. if there is no data in the retrieved context that could be used make sure that no made up answer is provided.

<img alt="structure" src="https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcad6071b-8d2f-4253-8d4e-27b5f7536917_1903x2270.png">

>  This is a good structure outline that we can use. I think the Approximate Nearest Neighbor search ANN is an interesting approach to receiving query context we want the model to use. This is a more complex (down-the-line) implementation but the complexity really refines the fine-tuning process. [SwirlAI](https://www.newsletter.swirlai.com/p/sai-notes-08-llm-based-chatbots-to)


- But for now we will probably be using the OpenAI platform to fine tune using prompts. Basically using two API calls. One that tunes the others responses. Kinda like the gpt builder nested in the gpt-4 chat. This is a good starting point. However, it would probably be pretty slow.


<img alt="fine-tuning-in-api" loading="lazy" width="900" decoding="async" data-nimg="1" class="mx-auto" style="color:transparent" sizes="(min-width: 1728px) 1728px, 100vw" srcset="https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=640&amp;q=90&amp;fm=webp&amp;fit=pad 640w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=750&amp;q=90&amp;fm=webp&amp;fit=pad 750w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=828&amp;q=90&amp;fm=webp&amp;fit=pad 828w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=1080&amp;q=90&amp;fm=webp&amp;fit=pad 1080w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=1200&amp;q=90&amp;fm=webp&amp;fit=pad 1200w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=3840&amp;q=90&amp;fm=webp 3840w" src="https://images.ctfassets.net/kftzwdyauwt9/51L0ZslvJmGuE7sJE1SVYX/7b362376a41a83be659f7b296774aa86/fine-tuning-in-api.gif?w=3840&amp;q=90&amp;fm=webp">
<br />

> It is pretty easy to set up a fine-tuning model using the OpenAI platform. [OpenAI](https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program/")


> **Sources**
>		- [SwirlAI](https://www.newsletter.swirlai.com/p/sai-notes-08-llm-based-chatbots-to)
>		- [Intro to fine-tuning OpenAI](https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program/")
> 		- [OpenAI fine-tuning doc](https://platform.openai.com/docs/guides/fine-tuning)
> 		- [Few Shot Fine-Tuning](https://arxiv.org/pdf/2402.15441)
> 		- [Avoiding jailbreaking/safety](https://arxiv.org/pdf/2310.03693)